import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import tensorflow as tf
from sklearn.tree import DecisionTreeClassifier
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate, GridSearchCV
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.neural_network import MLPClassifier
from sklearn.dummy import DummyClassifier



### Reading the csv file
data = pd.read_csv("adult_income.csv")


data.head()
data.info()


########## Trying to look at the condition of the data ##########
# Count of NaNs
missing_counts = data.isnull().sum()

# Count of "?" as missing indicator
question_mark_counts = (data == '?').sum()

# Combine into a DataFrame
missing_summary = pd.DataFrame({
    'nan_count': missing_counts,
    'question_mark_count': question_mark_counts
})

# Sort by total missing (NaN + "?")
missing_summary['total_missing'] = missing_summary['nan_count'] + missing_summary['question_mark_count']
missing_summary = missing_summary.sort_values(by='total_missing', ascending=False)

print(missing_summary)


### Checking all Data columns uniques values
print("occupation:", data['occupation'].unique())


print("workclass:", data['workclass'].unique())


print("education:", data['education'].unique())


print("education.num':", data['education.num'].unique())


print("relationship:", data['relationship'].unique())


print("marital.status:", data['marital.status'].unique())


print("race:", data['race'].unique())


print("sex:", data['sex'].unique())


print("capital.gain:", data['capital.gain'].unique())


print("capital.loss:", data['capital.loss'].unique())


print("hours.per.week:", data['hours.per.week'].unique())


print("native.country:", data['native.country'].unique())


print("income:", data['income'].unique())


print("age:", data['age'].unique())


#### Finding duplicate rows
duplicates = data[data.duplicated()]
print(duplicates)
num_duplicates = data.duplicated().sum()
print(f"Number of duplicate rows: {num_duplicates}")


# List of typical integer variables in Adult dataset
int_columns = ['age', 'fnlwgt', 'education.num', 'capital.gain', 'capital.loss', 'hours.per.week']

# Check which columns actually exist in your dataframe
existing_int_columns = [col for col in int_columns if col in data.columns]

# Plot each boxplot separately
for col in existing_int_columns:
    plt.figure(figsize=(6, 4))
    sns.boxplot(y=data[col])
    plt.title(f'Boxplot of {col}')
    plt.ylabel(col)
    plt.show()


########## Pre-processing steps starts from here ##########

### 1. Removing duplicate rows
df_adult_income = data.drop_duplicates()



### 2. Renaming the column name 'fnlwgt' to a better name for clear understanding 
df_adult_income = df_adult_income.rename(columns={'fnlwgt': 'population.weight'})


### 3. Renaming the column name 'education.num' to a better name for clear understanding 
df_adult_income = df_adult_income.rename(columns={'education.num': 'years.of.education'})


### 4. Completing the country names for better understanding 
df_adult_income['native.country'] = df_adult_income['native.country'].replace('South', 'South-Korea')
df_adult_income['native.country'] = df_adult_income['native.country'].replace('Hong', 'Hong-Kong')


### 5. Randomly modifying the column 'sex' values and then trying to fix them. 
sample_indices = df_adult_income.sample(n=2000, random_state=42).index
df_adult_income.loc[sample_indices, 'sex'] = df_adult_income.loc[sample_indices, 'sex'].replace({'Male': 'M', 'Female': 'F'})
df_adult_income['sex'] = df_adult_income['sex'].replace({'M': 'Male', 'F': 'Female'})



### 6. Removing country rows where values are null
# Count rows where country == '?'
num_question_mark = (df_adult_income['native.country'] == '?').sum()
print(f"Number of rows with country = '?': {num_question_mark}")


### 7. Keep only rows where the country is not '?'
df_adult_income= df_adult_income[df_adult_income['native.country'] != '?']
print(f"Shape after removing '?': {df_adult_income.shape}")


### 8. Filling in missing values for the columns 'workclass' and 'occupation' using DecisionTree Classifier

df = df_adult_income.copy()

# Replace '?' with NaN
df.replace('?', np.nan, inplace=True)

# Define features to use for prediction
features = ['education', 'marital.status', 'relationship', 'race',
            'sex', 'native.country', 'age', 'population.weight',
            'capital.gain', 'capital.loss', 'hours.per.week']

def impute_missing_column(df, target_col, features):
    df_copy = df.copy()
    
    # Encode target column
    le_target = LabelEncoder()
    
    # Split known and unknown
    df_known = df_copy[df_copy[target_col].notna()].copy()
    df_unknown = df_copy[df_copy[target_col].isna()].copy()
    
    # Drop rows where features are missing
    df_known = df_known.dropna(subset=features)
    
    # Encode target
    df_known[target_col + '_encoded'] = le_target.fit_transform(df_known[target_col])
    
    # Encode categorical features
    df_encoded = df_known[features].copy()
    for col in df_encoded.select_dtypes(include='object').columns:
        df_encoded[col] = LabelEncoder().fit_transform(df_encoded[col])
    
    # Train the decision tree
    tree = DecisionTreeClassifier(random_state=42)
    tree.fit(df_encoded, df_known[target_col + '_encoded'])
    
    # Prepare unknown data
    df_unknown_filled = df_unknown[features].copy()
    for col in df_unknown_filled.select_dtypes(include='object').columns:
        df_unknown_filled[col] = LabelEncoder().fit_transform(df_unknown_filled[col].fillna('Unknown'))
    
    # Fill any remaining missing numeric values (just in case)
    df_unknown_filled = df_unknown_filled.fillna(df_encoded.mean(numeric_only=True))
    
    # Predict
    preds = tree.predict(df_unknown_filled)
    
    # Fill in the original DataFrame
    df.loc[df[target_col].isna(), target_col] = le_target.inverse_transform(preds)

# Impute 'workclass'
impute_missing_column(df, 'workclass', features)

# Now, include 'workclass' as a feature to predict 'occupation'
features_with_workclass = features + ['workclass']
impute_missing_column(df, 'occupation', features_with_workclass)

print("Missing values after imputation:")
print("workclass:", df['workclass'].isna().sum())
print("occupation:", df['occupation'].isna().sum())



### 9. log1p (log(x+1)) to skewed variables

# Applying log1p (log(x+1)) to skewed variables
df['population.weight'] = np.log1p(df['population.weight'])
df['capital.gain'] = np.log1p(df['capital.gain'])
df['capital.loss'] = np.log1p(df['capital.loss'])




### 10. One hot encoding the categorical columns


categorical_cols = ['workclass', 'occupation', 'education', 'marital.status',
                    'relationship', 'race', 'sex', 'native.country']

# One-hot encode all categorical variables
# For logistic regression
df_logistic_regression = pd.get_dummies(df, columns=categorical_cols, drop_first=True, dtype=int)

# For neural network
df_neural_network = pd.get_dummies(df, columns=categorical_cols, drop_first=False, dtype=int)

# Encode target variable (if it's not already numeric)
df_logistic_regression['income'] = df_logistic_regression['income'].map({'<=50K': 0, '>50K': 1})
df_neural_network['income'] = df_neural_network['income'].map({'<=50K': 0, '>50K': 1})

# Check encoded DataFrame
print(df_logistic_regression.head())
print(df_neural_network.head())

print("Encoded values in df_logistic_regression['income']:", df_logistic_regression['income'].unique())
print("Encoded values in df_neural_network['income']:", df_neural_network['income'].unique())



########## LOGISTIC REGRESSION  MODEL IMPLEMENTATION ##########

# 1. Split into features and target
X = df_logistic_regression.drop('income', axis=1)
y = df_logistic_regression['income']

# 2. Train/test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=30, stratify=y)

# 3. Define pipeline: scaler + SMOTE + logistic regression
pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('smote', SMOTE(random_state=30)),
    ('clf', LogisticRegression(max_iter=1000, random_state=30))
])

# 4. Define hyperparameters to tune
param_grid = {
    'clf__C': [0.01, 0.1, 1, 10]
}

# 5. Define 4-fold stratified cross-validation
cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=30)

# 6. Use GridSearchCV to perform hyperparameter tuning with cross-validation
grid_search = GridSearchCV(
    estimator=pipeline,
    param_grid=param_grid,
    cv=cv,
    scoring='f1',           
    n_jobs=-1
)

# 7. Fit GridSearchCV on training data
grid_search.fit(X_train, y_train)

# 8. Print best hyperparameter and corresponding score
print("Best hyperparameter C:", grid_search.best_params_['clf__C'])
print(f"Best cross-validated F1 score: {grid_search.best_score_:.4f}")

# 9. Evaluate the best model on the test set
best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_test)
y_pred_logistic = y_pred

accuracy_lr = accuracy_score(y_test, y_pred)
conf_matrix_lr = confusion_matrix(y_test, y_pred)
report_lr = classification_report(y_test, y_pred)

print("\nFinal test set performance with best hyperparameters:")
print(f"Accuracy: {accuracy_lr:.4f}")
print("\nConfusion Matrix:")
print(conf_matrix_lr)
print("\nClassification Report:")
print(report_lr)



########## NEURAL NETWORK MODEL IMPLEMENTATION ##########


# 1. Split into features and target
X = df_neural_network.drop('income', axis=1)
y = df_neural_network['income']

# 2. Train/test split with stratification
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=30, stratify=y)

# 3. Define pipeline: scaler + SMOTE + MLPClassifier (neural network)
pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('smote', SMOTE(random_state=30)),
    ('clf', MLPClassifier(max_iter=1000, random_state=30))
])

# 4. Define hyperparameters to tune
param_grid = {
    'clf__hidden_layer_sizes': [(50,), (100,), (50, 50)],  # try different network sizes
    'clf__alpha': [0.0001, 0.001, 0.01],                  # regularization strength
    'clf__learning_rate_init': [0.001, 0.01]               # initial learning rate
}

# 5. Define 4-fold stratified cross-validation
cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=30)

# 6. Use GridSearchCV for hyperparameter tuning
grid_search = GridSearchCV(
    estimator=pipeline,
    param_grid=param_grid,
    cv=cv,
    scoring='f1',        # optimize for F1 score (balanced metric)
    n_jobs=-1
)

# 7. Fit GridSearchCV on training data
grid_search.fit(X_train, y_train)

# 8. Print best hyperparameters and corresponding score
print("Best hyperparameters:", grid_search.best_params_)
print(f"Best cross-validated F1 score: {grid_search.best_score_:.4f}")

# 9. Evaluate best model on test data
best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_test)
y_pred_nn = y_pred

accuracy_nn = accuracy_score(y_test, y_pred)
conf_matrix_nn = confusion_matrix(y_test, y_pred)
report_nn = classification_report(y_test, y_pred)

print("\nFinal test set performance with best hyperparameters:")
print(f"Accuracy: {accuracy_nn:.4f}")
print("\nConfusion Matrix:")
print(conf_matrix_nn)
print("\nClassification Report:")
print(report_nn)



########## BASELINE MODEL IMPLEMENTATION ##########

# 1. Split into features and target
X = df_neural_network.drop('income', axis=1)
y = df_neural_network['income']

# 2. Train/test split with stratification
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=30, stratify=y)

# 3. Evaluate on test data
baseline = DummyClassifier(strategy='most_frequent')
baseline.fit(X_train, y_train)
y_pred = baseline.predict(X_test)
y_pred_baseline = y_pred

accuracy_bl = accuracy_score(y_test, y_pred)
conf_matrix_bl = confusion_matrix(y_test, y_pred)
report_bl = classification_report(y_test, y_pred)

print("Baseline performance:")
print(f"Accuracy: {accuracy_bl:.4f}")
print("\nConfusion Matrix:")
print(conf_matrix_bl)
print("\nClassification Report:")
print(report_bl)


############### Human performance in our own user study############

# 1. Load the Excel file into DataFrame
data = pd.read_excel('Adult_income_prediction.xlsx')  # assuming ~100 rows

# 2. Define dictionary to map text labels to numeric 0 and 1
income_mapping = {
    '<=50K': 0,
    '>50K': 1
}

# 3. Apply mapping to actual and predicted columns
y_true = data['income_actual'].map(income_mapping)
y_pred = data['income_predicted'].map(income_mapping)

# 4. Calculate accuracy
accuracy_human = accuracy_score(y_true, y_pred)

# 5. Get detailed classification report as dictionary
report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)

# 6. Print overall accuracy
print(f"Overall Accuracy: {accuracy_human:.4f}\n")

# 7. Print per-class metrics nicely
for label in ['0', '1']:
    print(f"Metrics for class {label}:")
    print(f"  Precision: {report[label]['precision']:.4f}")
    print(f"  Recall:    {report[label]['recall']:.4f}")
    print(f"  F1 Score:  {report[label]['f1-score']:.4f}")
    print()

# 8. Optional: Print the full classification report table
print("Full Classification Report:")
print(classification_report(y_true, y_pred, zero_division=0))



########## MODEL COMPARISON BETWEEN LOGISTICS, NEURAL NETWORK , BASELINE MODEL  and HUMAN PREDICTION ##########

# 1. create function for model performance evaluation
def evaluate_model(name, y_true, y_pred):
    acc = accuracy_score(y_true, y_pred)
    report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)
    return {
        'Model': name,
        'Accuracy': round(acc, 4),

        'F1 (class 0)': round(report['0']['f1-score'], 4),
        'Recall (class 0)': round(report['0']['recall'], 4),
        'Precision (class 0)': round(report['0']['precision'], 4),
        
        'F1 (class 1)': round(report['1']['f1-score'], 4),
        'Recall (class 1)': round(report['1']['recall'], 4),
        'Precision (class 1)': round(report['1']['precision'], 4)
    }
# 2. Evaluating Result
results = [
    evaluate_model('Baseline (Majority)', y_test, y_pred_baseline),
    evaluate_model('Logistic Regression', y_test, y_pred_logistic),
    evaluate_model('Neural Network', y_test, y_pred_nn),
    evaluate_model('Human Prediction', y_true, y_pred)

]

summary_df = pd.DataFrame(results)

print("**Comparison summary:**")
print(summary_df)



########## MODEL COMPARISON VISUALIZATION AMONG 4 APPROACHES ##########

# Accuracies for the three models
models = ['Baseline (Majority)', 'Logistic Regression', 'Neural Network', 'Human Prediction' ]
accuracies = [accuracy_bl, accuracy_lr, accuracy_nn, accuracy_human]  

plt.figure(figsize=(8, 5))
plt.bar(models, accuracies, color=['gray', 'blue', 'green', 'yellow'])

plt.ylim(0, 1)  # Accuracy is between 0 and 1
plt.ylabel('Accuracy')
plt.title('Accuracy Comparison of Models')

for i, acc in enumerate(accuracies):
    plt.text(i, acc + 0.02, f'{acc:.3f}', ha='center')

plt.show()



